{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the **7th** Notebook in the clustering pipeline. It shows you how to evaluate the final clustering solution on outcomes and inputs. This solution could be chosen by hand, by using the NBclust pipeline or another method (like bootstrap). **PATRICIA THIS COULD BE USEFUL FOR WHICHEVER SOLUTION YOU DECIDE TO USE**.\n",
    "\n",
    "Use <u>***pappas_tadam***</u> virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to whatever directory GoodCopy is in\n",
    "\n",
    "home_dir = \"/home/l/lungboy/tadam/Project/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages and functions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(home_dir + 'GoodCopy/Functions')\n",
    "\n",
    "import FunctionsOOPGood as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Datasets\n",
    "\n",
    "data = func.DataSet(empty=True)\n",
    "data.open_DataSet(home_dir + \"GoodCopy/Objects/data_object\")\n",
    "\n",
    "data_matched = func.MatchedDataSet(empty=True)\n",
    "data_matched.open_MatchedDataSet(home_dir + \"GoodCopy/Objects/matched_data_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Labels\n",
    "\n",
    "agglo_labels = [pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_agglo_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "all_labels = [pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_all_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "hdb_labels = [pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_hdb_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "kmedoids_labels = [pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_kmedoids_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "snf_hdb_labels = [pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_snf_hdb_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "snf_spectral_labels =[pd.read_csv(home_dir + \"GoodCopy/EnsembleResults/{}_snf_spectral_labels.csv\".format(i), index_col= 0) for i in range(2,10)]\n",
    "\n",
    "labels = agglo_labels + all_labels + hdb_labels + kmedoids_labels + snf_hdb_labels + snf_spectral_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE YOUR FINAL LABEL SOLUTION HERE. Should be the form of a 1D array (ie list, numpy array, \n",
    "# pandas series, etc).\n",
    "\n",
    "final_solution = np.ravel(hdb_labels[6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Testing on Clusters\n",
    "Statistical Testing on clusters of final solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Statistical Tests\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Turn off all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "eval_output = data.EvaluateClusters(data = \"output\", labels = final_solution, range_type=\"quantile\", range_level = 0.5)\n",
    "\n",
    "eval_input = data.EvaluateClusters(data = \"input\", labels = final_solution)\n",
    "\n",
    "# Reset warnings to their default behavior (optional)\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing, only Significant Outcomes are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View significant output variables. The first dataframe contains categorical variables analyzes with chisquare\n",
    "# and the second contains continous analyzed with ANOVA.\n",
    "\n",
    "print(\"\\n\\033[1mSignificant Categorical Outcomes\\n\")\n",
    "display(eval_output[0][eval_output[0][\"pvalue\"] < 0.05])\n",
    "print(\"\\n\\033[1mSignificant Continuous Outcomes\\n\")\n",
    "display(eval_output[1][eval_output[1][\"pvalue\"] < 0.05])\n",
    "#display(eval_output[1][(eval_output[1][\"welch pvalue\"] <= 0.05) & (eval_output[1][\"valid\"] == False) | (eval_output[1][\"pvalue\"] <= 0.05) & (eval_output[1][\"valid\"] == True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value counts for Statistically Significant Categorical/Binary Outcome Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Counts for Each category for categorical variables. This one shows output variables.\n",
    "\n",
    "sig_vars_cat = eval_output[0][eval_output[0][\"pvalue\"] < 0.05].index.tolist()\n",
    "#sig_vars_cat.append(\"f34_pet\")\n",
    "\n",
    "#count_df_output_cat = pd.DataFrame(index = np.unique(final_solution))\n",
    "\n",
    "for i in sig_vars_cat:\n",
    "    \n",
    "    counts = func.DataSet.get_val_counts(data = data.outcome_bin_cat, labels = final_solution , var = i)\n",
    "    \n",
    "    print(\"\\n\\033[1m\",i,\"\\033[0m\\n\")\n",
    "    for j in range(len(counts)):\n",
    "        print(j,\"\\t\",\", \".join([f\"{key}: {value}\" for d in counts[j] for key, value in d.items()]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Median Statistics for Statistically Significant Continuous/Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View means for each continouos variable. This one shows output variables.\n",
    "\n",
    "sig_vars_cont = eval_output[1][eval_output[1].pvalue < 0.05].index\n",
    "\n",
    "mean_df_output_cont = pd.DataFrame(index = np.unique(final_solution))\n",
    "median_df_output_cont = pd.DataFrame(index = np.unique(final_solution))\n",
    "\n",
    "for i in sig_vars_cont:\n",
    "    \n",
    "    counts = func.DataSet.get_cluster_sum_var(data = data.outcome_cont_ord, labels = final_solution , var = i)\n",
    "    \n",
    "    mean_df_output_cont[i] = [x[0] for x in counts]\n",
    "    median_df_output_cont[i] = [x[1] for x in counts]\n",
    "    \n",
    "print(\"\\n\\033[1mMean\\n\")\n",
    "display(mean_df_output_cont)\n",
    "print(\"\\n\\033[1mMedian\\n\")\n",
    "median_df_output_cont"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing, only Significant Inputs are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View significant input variables. The first dataframe contains categorical variables analyzes with chisquare\n",
    "# and the second contains continous analyzed with ANOVA.\n",
    "\n",
    "print(\"\\n\\033[1mSignificant Categorical Inputs\\n\")\n",
    "display(eval_input[0][eval_input[0][\"pvalue\"] < 0.05])\n",
    "print(\"\\n\\033[1mSignificant Continuous Inputs\\n\")\n",
    "display(eval_input[1][eval_input[1].pvalue < 0.05])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value counts for Statistically Significant Categorical/Binary Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Counts for Each category for categorical variables. This one shows output variables.\n",
    "\n",
    "sig_vars_cat = eval_input[0][eval_input[0][\"pvalue\"] < 0.05].index.tolist() \n",
    "\n",
    "count_df_output_cat = pd.DataFrame(index = np.unique(final_solution))\n",
    "\n",
    "for i in sig_vars_cat:\n",
    "    \n",
    "    counts = func.DataSet.get_val_counts(data = data.input_data_unscaled, labels = final_solution , var = i)\n",
    "    \n",
    "    print(\"\\n\\033[1m\",i,\"\\033[0m\\n\")\n",
    "    for j in range(len(counts)):\n",
    "        print(j,\"\\t\",\", \".join([f\"{key}: {value}\" for d in counts[j] for key, value in d.items()]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Median Statistics for Statistically Significant Continuous/Ordinal Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Counts for Each category for categorical variables. This one shows output variables.\n",
    "\n",
    "sig_vars_cont = eval_input[1][eval_input[1].pvalue < 0.05].index\n",
    "\n",
    "mean_df_input_cont = pd.DataFrame(index = np.unique(final_solution))\n",
    "median_df_input_cont = pd.DataFrame(index = np.unique(final_solution))\n",
    "\n",
    "for i in sig_vars_cont:\n",
    "    \n",
    "    counts = func.DataSet.get_cluster_sum_var(data = data.input_data_unscaled, labels = final_solution , var = i)\n",
    "\n",
    "    mean_df_input_cont[i] = [x[0] for x in counts]\n",
    "    median_df_input_cont[i] = [x[1] for x in counts]\n",
    "    \n",
    "    mean_df_input_cont = mean_df_input_cont.copy()\n",
    "    median_df_input_cont = median_df_input_cont.copy()\n",
    "    \n",
    "print(\"\\n\\033[1mMean\\n\")\n",
    "display(mean_df_input_cont)\n",
    "print(\"\\n\\033[1mMedian\\n\")\n",
    "median_df_input_cont"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretable classifier results for Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_interpretable_vars = data.random_forest_importance(labels = final_solution, n_class= len(np.unique(final_solution)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1mImportant Input Variables in Differentiating between Clusters\\n\")\n",
    "input_interpretable_vars.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biomarker Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretable classifier results for Biomarker Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping data by filling in NAs\n",
    "\n",
    "df = data.bio_data.copy()\n",
    "\n",
    "mean_values = df[~np.isinf(df)].mean()\n",
    "\n",
    "# Step 2: Replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Step 3: Fill NaN values with the calculated mean\n",
    "df.fillna(mean_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bio_interpretable_vars = data.random_forest_importance(data = df,labels = final_solution, n_class= len(np.unique(final_solution)))\n",
    "\n",
    "eval_bio = data.EvaluateClusters(labels = final_solution, data=\"bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1mSignificant Continuous Biomarker Variables\\n\")\n",
    "display(eval_bio[1][eval_bio[1].pvalue < 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1mImportant Biomarker Variables in Differentiating between Clusters\\n\")\n",
    "bio_interpretable_vars.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Stuff\n",
    "\n",
    "sample workflows for potential things you might want to explore in a solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at differences between PE and control within one cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Extract cluster 1 and do random forest importance to see what differentiates the controls from PE\n",
    "\n",
    "cluster_number = 5\n",
    "\n",
    "data_temp = data.input_data_unscaled.copy()\n",
    "data_temp[\"labels\"] = final_solution\n",
    "data_temp[\"PE\"] = data.pe_labels.copy()\n",
    "\n",
    "data_temp = data_temp[data_temp[\"labels\"] == cluster_number]\n",
    "\n",
    "diff = data_temp[\"PE\"]\n",
    "\n",
    "res = data.random_forest_importance(data=data_temp.drop(columns=[\"labels\",\"PE\"]),labels=diff,n_class = 2)\n",
    "\n",
    "res1 = data.EvaluateClusters(labels = diff, data=\"input\", subset = list(data_temp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1mImportant Input Variables in Differentiating between PE and Control within Cluster {}\\n\".format(cluster_number))\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1mSignificant Categorical Inputs between PE and control in Cluster {}\\n\".format(cluster_number))\n",
    "display(res1[0][res1[0].pvalue < 0.05])\n",
    "print(\"\\n\\033[1mSignificant Continuous Inputs between PE and control in Cluster {}\\n\".format(cluster_number))\n",
    "display(res1[1][res1[1].pvalue < 0.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pappas_tadam",
   "language": "python",
   "name": "pappas_tadam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
